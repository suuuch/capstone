{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_files(file_dir, ratio):\n",
    "    '''\n",
    "    Args:\n",
    "        file_dir: file directory\n",
    "    Returns:\n",
    "        list of images and labels\n",
    "    '''\n",
    "    cats = []\n",
    "    label_cats = []\n",
    "    dogs = []\n",
    "    label_dogs = []\n",
    "    for file in os.listdir(file_dir):\n",
    "        name = file.split(sep='.')\n",
    "        if name[0]=='cat':\n",
    "            cats.append(file_dir + file)\n",
    "            label_cats.append(0)\n",
    "        else:\n",
    "            dogs.append(file_dir + file)\n",
    "            label_dogs.append(1)\n",
    "    print('There are %d cats\\nThere are %d dogs' %(len(cats), len(dogs)))\n",
    "    \n",
    "    image_list = np.hstack((cats, dogs))\n",
    "    label_list = np.hstack((label_cats, label_dogs))\n",
    "    \n",
    "    temp = np.array([image_list, label_list])\n",
    "    temp = temp.transpose()\n",
    "    np.random.shuffle(temp)   \n",
    "    \n",
    "    all_image_list = temp[:, 0]\n",
    "    all_label_list = temp[:, 1]\n",
    "    \n",
    "    n_sample = len(all_label_list)\n",
    "    n_val = math.ceil(n_sample*ratio) # number of validation samples\n",
    "    n_train = n_sample - n_val # number of trainning samples\n",
    "    \n",
    "    tra_images = all_image_list[0:n_train]\n",
    "    tra_labels = all_label_list[0:n_train]\n",
    "    tra_labels = [int(float(i)) for i in tra_labels]\n",
    "    val_images = all_image_list[n_train:-1]\n",
    "    val_labels = all_label_list[n_train:-1]\n",
    "    val_labels = [int(float(i)) for i in val_labels]\n",
    "    \n",
    "    \n",
    "    \n",
    "    return tra_images,tra_labels,val_images,val_labels\n",
    "\n",
    "\n",
    "#%%\n",
    "\n",
    "def get_batch(image, label, image_W, image_H, batch_size, capacity):\n",
    "    '''\n",
    "    Args:\n",
    "        image: list type\n",
    "        label: list type\n",
    "        image_W: image width\n",
    "        image_H: image height\n",
    "        batch_size: batch size\n",
    "        capacity: the maximum elements in queue\n",
    "    Returns:\n",
    "        image_batch: 4D tensor [batch_size, width, height, 3], dtype=tf.float32\n",
    "        label_batch: 1D tensor [batch_size], dtype=tf.int32\n",
    "    '''\n",
    "    \n",
    "    image = tf.cast(image, tf.string)\n",
    "    label = tf.cast(label, tf.int32)\n",
    "\n",
    "    # make an input queue\n",
    "    input_queue = tf.train.slice_input_producer([image, label])\n",
    "    \n",
    "    label = input_queue[1]\n",
    "    image_contents = tf.read_file(input_queue[0])\n",
    "    image = tf.image.decode_jpeg(image_contents, channels=3)\n",
    "    \n",
    "    ######################################\n",
    "    # data argumentation should go to here\n",
    "    ######################################\n",
    "    \n",
    "    image = tf.image.resize_image_with_crop_or_pad(image, image_W, image_H)    \n",
    "    # if you want to test the generated batches of images, you might want to comment the following line.\n",
    "    \n",
    "    # 如果想看到正常的图片，请注释掉111行（标准化）和 130行（image_batch = tf.cast(image_batch, tf.float32)）\n",
    "    # 训练时，不要注释掉！\n",
    "    image = tf.image.per_image_standardization(image)\n",
    "    \n",
    "    image_batch, label_batch = tf.train.batch([image, label],\n",
    "                                                batch_size= batch_size,\n",
    "                                                num_threads= 64, \n",
    "                                                capacity = capacity)\n",
    "    \n",
    "    label_batch = tf.reshape(label_batch, [batch_size])\n",
    "    image_batch = tf.cast(image_batch, tf.float32)\n",
    "    \n",
    "    return image_batch, label_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(images, batch_size, n_classes):\n",
    "    '''Build the model\n",
    "    Args:\n",
    "        images: image batch, 4D tensor, tf.float32, [batch_size, width, height, channels]\n",
    "    Returns:\n",
    "        output tensor with the computed logits, float, [batch_size, n_classes]\n",
    "    '''\n",
    "    #conv1, shape = [kernel size, kernel size, channels, kernel numbers]\n",
    "\n",
    "    weights = tf.get_variable('weights',\n",
    "                              shape=[3, 3, 3, 16],\n",
    "                              dtype=tf.float32,\n",
    "                              initializer=tf.truncated_normal_initializer(stddev=0.1, dtype=tf.float32))\n",
    "    biases = tf.get_variable('biases',\n",
    "                             shape=[16],\n",
    "                             dtype=tf.float32,\n",
    "                             initializer=tf.constant_initializer(0.1))\n",
    "    conv = tf.nn.conv2d(images, weights, strides=[1, 1, 1, 1], padding='SAME')\n",
    "    pre_activation = tf.nn.bias_add(conv, biases)\n",
    "    conv1 = tf.nn.relu(pre_activation, name='conv1')\n",
    "\n",
    "    #pool1 and norm1   \n",
    "\n",
    "    pool1 = tf.nn.max_pool(conv1, ksize=[1, 3, 3, 1], strides=[1, 2, 2, 1],\n",
    "                           padding='SAME', name='pooling1')\n",
    "    norm1 = tf.nn.lrn(pool1, depth_radius=4, bias=1.0, alpha=0.001 / 9.0,\n",
    "                      beta=0.75, name='norm1')\n",
    "\n",
    "    #conv2\n",
    "\n",
    "    weights = tf.get_variable('weights',\n",
    "                              shape=[3, 3, 16, 16],\n",
    "                              dtype=tf.float32,\n",
    "                              initializer=tf.truncated_normal_initializer(stddev=0.1, dtype=tf.float32))\n",
    "    biases = tf.get_variable('biases',\n",
    "                             shape=[16],\n",
    "                             dtype=tf.float32,\n",
    "                             initializer=tf.constant_initializer(0.1))\n",
    "    conv = tf.nn.conv2d(norm1, weights, strides=[1, 1, 1, 1], padding='SAME')\n",
    "    pre_activation = tf.nn.bias_add(conv, biases)\n",
    "    conv2 = tf.nn.relu(pre_activation, name='conv2')\n",
    "\n",
    "    #pool2 and norm2\n",
    "    norm2 = tf.nn.lrn(conv2, depth_radius=4, bias=1.0, alpha=0.001 / 9.0,\n",
    "                      beta=0.75, name='norm2')\n",
    "    pool2 = tf.nn.max_pool(norm2, ksize=[1, 3, 3, 1], strides=[1, 1, 1, 1],\n",
    "                           padding='SAME', name='pooling2')\n",
    "\n",
    "    #local3\n",
    "    reshape = tf.reshape(pool2, shape=[batch_size, -1])\n",
    "    dim = reshape.get_shape()[1].value\n",
    "    weights = tf.get_variable('weights',\n",
    "                              shape=[dim, 128],\n",
    "                              dtype=tf.float32,\n",
    "                              initializer=tf.truncated_normal_initializer(stddev=0.005, dtype=tf.float32))\n",
    "    biases = tf.get_variable('biases',\n",
    "                             shape=[128],\n",
    "                             dtype=tf.float32,\n",
    "                             initializer=tf.constant_initializer(0.1))\n",
    "    local3 = tf.nn.relu(tf.matmul(reshape, weights) + biases, name='local3')\n",
    "\n",
    "    #local4\n",
    "    weights = tf.get_variable('weights',\n",
    "                              shape=[128, 128],\n",
    "                              dtype=tf.float32,\n",
    "                              initializer=tf.truncated_normal_initializer(stddev=0.005, dtype=tf.float32))\n",
    "    biases = tf.get_variable('biases',\n",
    "                             shape=[128],\n",
    "                             dtype=tf.float32,\n",
    "                             initializer=tf.constant_initializer(0.1))\n",
    "    local4 = tf.nn.relu(tf.matmul(local3, weights) + biases, name='local4')\n",
    "\n",
    "    # softmax\n",
    "    weights = tf.get_variable('softmax_linear',\n",
    "                              shape=[128, n_classes],\n",
    "                              dtype=tf.float32,\n",
    "                              initializer=tf.truncated_normal_initializer(stddev=0.005, dtype=tf.float32))\n",
    "    biases = tf.get_variable('biases',\n",
    "                             shape=[n_classes],\n",
    "                             dtype=tf.float32,\n",
    "                             initializer=tf.constant_initializer(0.1))\n",
    "    softmax_linear = tf.add(tf.matmul(local4, weights), biases, name='softmax_linear')\n",
    "\n",
    "    return softmax_linear\n",
    "\n",
    "\n",
    "def losses(logits, labels):\n",
    "    '''Compute loss from logits and labels\n",
    "    Args:\n",
    "        logits: logits tensor, float, [batch_size, n_classes]\n",
    "        labels: label tensor, tf.int32, [batch_size]\n",
    "        \n",
    "    Returns:\n",
    "        loss tensor of float type\n",
    "    '''\n",
    "    with tf.variable_scope('loss') as scope:\n",
    "        cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits \\\n",
    "            (logits=logits, labels=labels, name='xentropy_per_example')\n",
    "        loss = tf.reduce_mean(cross_entropy, name='loss')\n",
    "        tf.summary.scalar(scope.name + '/loss', loss)\n",
    "    return loss\n",
    "\n",
    "\n",
    "def trainning(loss, learning_rate):\n",
    "    '''Training ops, the Op returned by this function is what must be passed to \n",
    "        'sess.run()' call to cause the model to train.\n",
    "        \n",
    "    Args:\n",
    "        loss: loss tensor, from losses()\n",
    "        \n",
    "    Returns:\n",
    "        train_op: The op for trainning\n",
    "    '''\n",
    "    with tf.name_scope('optimizer'):\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "        global_step = tf.Variable(0, name='global_step', trainable=False)\n",
    "        train_op = optimizer.minimize(loss, global_step=global_step)\n",
    "    return train_op\n",
    "\n",
    "\n",
    "def evaluation(logits, labels):\n",
    "    \"\"\"Evaluate the quality of the logits at predicting the label.\n",
    "    Args:\n",
    "      logits: Logits tensor, float - [batch_size, NUM_CLASSES].\n",
    "      labels: Labels tensor, int32 - [batch_size], with values in the\n",
    "        range [0, NUM_CLASSES).\n",
    "    Returns:\n",
    "      A scalar int32 tensor with the number of examples (out of batch_size)\n",
    "      that were predicted correctly.\n",
    "    \"\"\"\n",
    "    with tf.variable_scope('accuracy') as scope:\n",
    "        correct = tf.nn.in_top_k(logits, labels, 1)\n",
    "        correct = tf.cast(correct, tf.float16)\n",
    "        accuracy = tf.reduce_mean(correct)\n",
    "        tf.summary.scalar(scope.name + '/accuracy', accuracy)\n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# you need to change the directories to yours.\n",
    "train_dir = 'train/'\n",
    "logs_train_dir = 'logs/train/'\n",
    "logs_val_dir = 'logs/val/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N_CLASSES = 2\n",
    "IMG_W = 208  # resize the image, if the input image is too large, training will be very slow.\n",
    "IMG_H = 208\n",
    "RATIO = 0.2 # take 20% of dataset as validation data \n",
    "BATCH_SIZE = 64\n",
    "CAPACITY = 2000\n",
    "MAX_STEP = 6000 # with current parameters, it is suggested to use MAX_STEP>10k\n",
    "learning_rate = 0.0001 # with current parameters, it is suggested to use learning rate<0.0001\n",
    "\n",
    "\n",
    "\n",
    "def run_training():\n",
    "    \n",
    "\n",
    "    \n",
    "    train, train_label, val, val_label = get_files(train_dir, RATIO)\n",
    "    train_batch, train_label_batch = get_batch(train,\n",
    "                                                  train_label,\n",
    "                                                  IMG_W,\n",
    "                                                  IMG_H,\n",
    "                                                  BATCH_SIZE, \n",
    "                                                  CAPACITY)\n",
    "    val_batch, val_label_batch = get_batch(val,\n",
    "                                                  val_label,\n",
    "                                                  IMG_W,\n",
    "                                                  IMG_H,\n",
    "                                                  BATCH_SIZE, \n",
    "                                                  CAPACITY)\n",
    "    \n",
    "\n",
    "    \n",
    "    x = tf.placeholder(tf.float32, shape=[BATCH_SIZE, IMG_W, IMG_H, 3])\n",
    "    y_ = tf.placeholder(tf.int16, shape=[BATCH_SIZE])\n",
    "    \n",
    "    logits = inference(x, BATCH_SIZE, N_CLASSES)\n",
    "    loss = losses(logits, y_)  \n",
    "    acc = evaluation(logits, y_)\n",
    "    train_op = trainning(loss, learning_rate)\n",
    "    \n",
    "    \n",
    "             \n",
    "    with tf.Session() as sess:\n",
    "        saver = tf.train.Saver()\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        coord = tf.train.Coordinator()\n",
    "        threads = tf.train.start_queue_runners(sess= sess, coord=coord)\n",
    "        \n",
    "        summary_op = tf.summary.merge_all()        \n",
    "        train_writer = tf.summary.FileWriter(logs_train_dir, sess.graph)\n",
    "        val_writer = tf.summary.FileWriter(logs_val_dir, sess.graph)\n",
    "    \n",
    "        try:\n",
    "            for step in np.arange(MAX_STEP):\n",
    "                if coord.should_stop():\n",
    "                        break\n",
    "                \n",
    "                tra_images,tra_labels = sess.run([train_batch, train_label_batch])\n",
    "                _, tra_loss, tra_acc = sess.run([train_op, loss, acc],\n",
    "                                                feed_dict={x:tra_images, y_:tra_labels})\n",
    "                if step % 50 == 0:\n",
    "                    print('Step %d, train loss = %.2f, train accuracy = %.2f%%' %(step, tra_loss, tra_acc*100.0))\n",
    "                    summary_str = sess.run(summary_op)\n",
    "                    train_writer.add_summary(summary_str, step)\n",
    "                    \n",
    "                if step % 200 == 0 or (step + 1) == MAX_STEP:\n",
    "                    val_images, val_labels = sess.run([val_batch, val_label_batch])\n",
    "                    val_loss, val_acc = sess.run([loss, acc], \n",
    "                                                 feed_dict={x:val_images, y_:val_labels})\n",
    "                    print('**  Step %d, val loss = %.2f, val accuracy = %.2f%%  **' %(step, val_loss, val_acc*100.0))\n",
    "                    summary_str = sess.run(summary_op)\n",
    "                    val_writer.add_summary(summary_str, step)  \n",
    "                                    \n",
    "                if step % 2000 == 0 or (step + 1) == MAX_STEP:\n",
    "                    checkpoint_path = os.path.join(logs_train_dir, 'model.ckpt')\n",
    "                    saver.save(sess, checkpoint_path, global_step=step)\n",
    "                    \n",
    "        except tf.errors.OutOfRangeError:\n",
    "            print('Done training -- epoch limit reached')\n",
    "        finally:\n",
    "            coord.request_stop()           \n",
    "        coord.join(threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def get_one_image(train):\n",
    "    '''Randomly pick one image from training data\n",
    "    Return: ndarray\n",
    "    '''\n",
    "    n = len(train)\n",
    "    ind = np.random.randint(0, n)\n",
    "    img_dir = train[ind]\n",
    "\n",
    "    image = Image.open(img_dir)\n",
    "    plt.imshow(image)\n",
    "    image = image.resize([208, 208])\n",
    "    image = np.array(image)\n",
    "    return image\n",
    "\n",
    "def evaluate_one_image():\n",
    "    '''Test one image against the saved models and parameters\n",
    "    '''\n",
    "\n",
    "    # you need to change the directories to yours.\n",
    "    train_dir = '/home/kevin/tensorflow/cats_vs_dogs/data/train/'\n",
    "    train, train_label = get_files(train_dir)\n",
    "    image_array = get_one_image(train)\n",
    "\n",
    "    with tf.Graph().as_default():\n",
    "        BATCH_SIZE = 1\n",
    "        N_CLASSES = 2\n",
    "\n",
    "        image = tf.cast(image_array, tf.float32)\n",
    "        image = tf.image.per_image_standardization(image)\n",
    "        image = tf.reshape(image, [1, 208, 208, 3])\n",
    "\n",
    "        logit = inference(image, BATCH_SIZE, N_CLASSES)\n",
    "\n",
    "        logit = tf.nn.softmax(logit)\n",
    "\n",
    "        x = tf.placeholder(tf.float32, shape=[208, 208, 3])\n",
    "\n",
    "        # you need to change the directories to yours.\n",
    "        logs_train_dir = '/home/kevin/tensorflow/cats_vs_dogs/logs/train/'\n",
    "\n",
    "        saver = tf.train.Saver()\n",
    "\n",
    "        with tf.Session() as sess:\n",
    "\n",
    "            print(\"Reading checkpoints...\")\n",
    "            ckpt = tf.train.get_checkpoint_state(logs_train_dir)\n",
    "            if ckpt and ckpt.model_checkpoint_path:\n",
    "                global_step = ckpt.model_checkpoint_path.split('/')[-1].split('-')[-1]\n",
    "                saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "                print('Loading success, global_step is %s' % global_step)\n",
    "            else:\n",
    "                print('No checkpoint file found')\n",
    "\n",
    "            prediction = sess.run(logit, feed_dict={x: image_array})\n",
    "            max_index = np.argmax(prediction)\n",
    "            if max_index == 0:\n",
    "                print('This is a cat with possibility %.6f' % prediction[:, 0])\n",
    "            else:\n",
    "                print('This is a dog with possibility %.6f' % prediction[:, 1])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
