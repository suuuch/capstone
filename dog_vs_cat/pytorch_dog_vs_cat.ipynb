{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import datasets,transforms, models\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.autograd import Variable \n",
    "import time\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = \".\"\n",
    "transform = transforms.Compose([transforms.CenterCrop(224),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize([0.5,0.5,0.5], [0.5,0.5,0.5])])\n",
    "\n",
    "data_image = {x:datasets.ImageFolder(root = os.path.join(path,x),\n",
    "                                     transform = transform)\n",
    "              for x in [\"train\", \"val\"]}\n",
    "\n",
    "data_loader_image = {x:torch.utils.data.DataLoader(dataset=data_image[x],\n",
    "                                                batch_size = 4,\n",
    "                                                shuffle = True)\n",
    "                     for x in [\"train\", \"val\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "use_gpu = torch.cuda.is_available()\n",
    "print(use_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classes = data_image[\"train\"].classes\n",
    "classes_index = data_image[\"train\"].class_to_idx\n",
    "print(classes)\n",
    "print(classes_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(u\"训练集个数:\", len(data_image[\"train\"]))\n",
    "print(u\"验证集个数:\", len(data_image[\"val\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, y_train = next(iter(data_loader_image[\"train\"]))\n",
    "mean = [0.5,0.5,0.5]\n",
    "std  = [0.5,0.5,0.5]\n",
    "img = torchvision.utils.make_grid(X_train)\n",
    "img = img.numpy().transpose((1,2,0))\n",
    "img = img*std+mean\n",
    "\n",
    "print([classes[i] for i in y_train])\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = models.vgg16(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for parma in model.parameters():\n",
    "    parma.requires_grad = False\n",
    "\n",
    "model.classifier = torch.nn.Sequential(torch.nn.Linear(25088, 4096),\n",
    "                                       torch.nn.ReLU(),\n",
    "                                       torch.nn.Dropout(p=0.5),\n",
    "                                       torch.nn.Linear(4096, 4096),\n",
    "                                       torch.nn.ReLU(),\n",
    "                                       torch.nn.Dropout(p=0.5),\n",
    "                                       torch.nn.Linear(4096, 2))\n",
    "\n",
    "for index, parma in enumerate(model.classifier.parameters()):\n",
    "    if index == 6:\n",
    "        parma.requires_grad = True\n",
    "    \n",
    "if use_gpu:\n",
    "    model = model.cuda()\n",
    "\n",
    "\n",
    "cost = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.classifier.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_epochs = 1\n",
    "for epoch in range(n_epochs):\n",
    "    since = time.time()\n",
    "    print(\"Epoch{}/{}\".format(epoch, n_epochs))\n",
    "    print(\"-\"*10)\n",
    "    for param in [\"train\", \"val\"]:\n",
    "        if param == \"train\":\n",
    "            model.train = True\n",
    "        else:\n",
    "            model.train = False\n",
    "\n",
    "        running_loss = 0.0\n",
    "        running_correct = 0 \n",
    "        batch = 0\n",
    "        for data in data_loader_image[param]:\n",
    "            batch += 1\n",
    "            X, y = data\n",
    "            if use_gpu:\n",
    "                X, y  = Variable(X.cuda()), Variable(y.cuda())\n",
    "            else:\n",
    "                X, y = Variable(X), Variable(y)\n",
    "        \n",
    "            optimizer.zero_grad()\n",
    "            y_pred = model(X)\n",
    "            _, pred = torch.max(y_pred.data, 1)\n",
    "        \n",
    "            loss = cost(y_pred, y)\n",
    "            if param ==\"train\":\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            running_loss += loss.data[0]\n",
    "            running_correct += torch.sum(pred == y.data)\n",
    "            if batch%500 == 0 and param ==\"train\":\n",
    "                print(\"Batch {}, Train Loss:{:.4f}, Train ACC:{:.4f}\".format(\n",
    "                      batch, running_loss/(4*batch), 100*running_correct/(4*batch)))\n",
    "            \n",
    "        epoch_loss = running_loss/len(data_image[param])\n",
    "        epoch_correct = 100*running_correct/len(data_image[param])\n",
    "\n",
    "        print(\"{}  Loss:{:.4f},  Correct{:.4f}\".format(param, epoch_loss, epoch_correct))\n",
    "    now_time = time.time() - since   \n",
    "    print(\"Training time is:{:.0f}m {:.0f}s\".format(now_time//60, now_time%60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"model_vgg16_finetune.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_test_img = datasets.ImageFolder(root=\"test\",\n",
    "                                     transform = transform)\n",
    "data_loader_test_img = torch.utils.data.DataLoader(dataset=data_test_img,\n",
    "                                                   batch_size = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_loader_test_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image, label = next(iter(data_loader_test_img))\n",
    "images = Variable(image.cuda())\n",
    "y_pred = model(images)\n",
    "_, pred = torch.max(y_pred.data, 1)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img = torchvision.utils.make_grid(image)\n",
    "img = img.numpy().transpose(1,2,0)\n",
    "mean = [0.5,0.5,0.5]\n",
    "std  = [0.5,0.5,0.5]\n",
    "img = img*std+mean\n",
    "print(\"Pred Label:\",[classes[i] for i in pred])\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TestImageFolder(data.Dataset):\n",
    "    def __init__(self, root, transform=None):\n",
    "        images = []\n",
    "        for filename in sorted(glob.glob(test_path + \"*.jpg\")):\n",
    "            images.append('{}'.format(filename))\n",
    "\n",
    "        self.root = root\n",
    "        self.imgs = images\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        filename = self.imgs[index]\n",
    "        img = Image.open(os.path.join(self.root, filename))\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        return img, filename\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test(test_loader, model):\n",
    "    csv_map = collections.defaultdict(float)\n",
    "    \n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "    \n",
    "    for aug in range(nb_aug):\n",
    "        print(\"   * Predicting on test augmentation {}\".format(aug + 1))\n",
    "        \n",
    "        for i, (images, filepath) in enumerate(test_loader):\n",
    "            # pop extension, treat as id to map\n",
    "            filepath = os.path.splitext(os.path.basename(filepath[0]))[0]\n",
    "            filepath = int(filepath)\n",
    "\n",
    "            image_var = torch.autograd.Variable(images, volatile=True)\n",
    "            y_pred = model(image_var)\n",
    "            # get the index of the max log-probability\n",
    "            smax = nn.Softmax()\n",
    "            smax_out = smax(y_pred)[0]\n",
    "            cat_prob = smax_out.data[0]\n",
    "            dog_prob = smax_out.data[1]\n",
    "            prob = dog_prob\n",
    "            if cat_prob > dog_prob:\n",
    "                prob = 1 - cat_prob\n",
    "            prob = np.around(prob, decimals=4)\n",
    "            prob = np.clip(prob, clip, 1-clip)\n",
    "            csv_map[filepath] += (prob / nb_aug)\n",
    "\n",
    "    sub_fn = submission_path + '{0}epoch_{1}clip_{2}runs'.format(epochs, clip, nb_runs)\n",
    "    \n",
    "    for arch in archs:\n",
    "        sub_fn += \"_{}\".format(arch)\n",
    "        \n",
    "    print(\"Writing Predictions to CSV...\")\n",
    "    with open(sub_fn + '.csv', 'w') as csvfile:\n",
    "        fieldnames = ['id', 'label']\n",
    "        csv_w = csv.writer(csvfile)\n",
    "        csv_w.writerow(('id', 'label'))\n",
    "        for row in sorted(csv_map.items()):\n",
    "            csv_w.writerow(row)\n",
    "    print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testdir = './data'\n",
    "test_loader = data.DataLoader(\n",
    "    TestImageFolder(testdir,\n",
    "                    transforms.Compose([\n",
    "                        # transforms.Lambda(shear),\n",
    "                        transforms.Scale(256),\n",
    "                        transforms.CenterCrop(224),\n",
    "                        transforms.RandomHorizontalFlip(),\n",
    "                        transforms.ToTensor(),\n",
    "                        normalize,\n",
    "                    ])),\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    num_workers=1,\n",
    "    pin_memory=False)\n",
    "\n",
    "test(test_loader, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
