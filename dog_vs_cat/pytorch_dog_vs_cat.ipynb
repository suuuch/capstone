{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import datasets,transforms, models\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.autograd import Variable \n",
    "import time\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"./data\"\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "transform = transforms.Compose([\n",
    "                             # transforms.Lambda(shear),\n",
    "                             transforms.RandomSizedCrop(224),\n",
    "                             transforms.RandomHorizontalFlip(),\n",
    "                             transforms.ToTensor(),\n",
    "                             normalize,\n",
    "                                 ])\n",
    "\n",
    "data_image = {x:datasets.ImageFolder(root = os.path.join(path,x),\n",
    "                                     transform = transform)\n",
    "              for x in [\"train\", \"val\"]}\n",
    "\n",
    "data_loader_image = {x:torch.utils.data.DataLoader(dataset=data_image[x],\n",
    "                                                num_workers=4,\n",
    "                                                batch_size=8,\n",
    "                                                pin_memory=True,\n",
    "                                                shuffle = True)\n",
    "                     for x in [\"train\", \"val\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_gpu = torch.cuda.is_available()\n",
    "print(use_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = data_image[\"train\"].classes\n",
    "classes_index = data_image[\"train\"].class_to_idx\n",
    "print(classes)\n",
    "print(classes_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(u\"训练集个数:\", len(data_image[\"train\"]))\n",
    "print(u\"验证集个数:\", len(data_image[\"val\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = next(iter(data_loader_image[\"train\"]))\n",
    "mean = [0.5,0.5,0.5]\n",
    "std  = [0.5,0.5,0.5]\n",
    "img = torchvision.utils.make_grid(X_train)\n",
    "img = img.numpy().transpose((1,2,0))\n",
    "img = img*std+mean\n",
    "\n",
    "print([classes[i] for i in y_train])\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.vgg16(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d (3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace)\n",
      "    (2): Conv2d (64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace)\n",
      "    (4): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
      "    (5): Conv2d (64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): ReLU(inplace)\n",
      "    (7): Conv2d (128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): ReLU(inplace)\n",
      "    (9): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
      "    (10): Conv2d (128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace)\n",
      "    (12): Conv2d (256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): ReLU(inplace)\n",
      "    (14): Conv2d (256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): ReLU(inplace)\n",
      "    (16): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
      "    (17): Conv2d (256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): ReLU(inplace)\n",
      "    (19): Conv2d (512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (20): ReLU(inplace)\n",
      "    (21): Conv2d (512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (22): ReLU(inplace)\n",
      "    (23): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
      "    (24): Conv2d (512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (25): ReLU(inplace)\n",
      "    (26): Conv2d (512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (27): ReLU(inplace)\n",
      "    (28): Conv2d (512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (29): ReLU(inplace)\n",
      "    (30): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=25088, out_features=4096)\n",
      "    (1): ReLU(inplace)\n",
      "    (2): Dropout(p=0.5)\n",
      "    (3): Linear(in_features=4096, out_features=4096)\n",
      "    (4): ReLU(inplace)\n",
      "    (5): Dropout(p=0.5)\n",
      "    (6): Linear(in_features=4096, out_features=1000)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-2\n",
    "for parma in model.parameters():\n",
    "    parma.requires_grad = False\n",
    "\n",
    "model.classifier = torch.nn.Sequential(torch.nn.Linear(25088, 4096),\n",
    "                                       torch.nn.ReLU(),\n",
    "                                       torch.nn.Dropout(p=0.5),\n",
    "                                       torch.nn.Linear(4096, 1024),\n",
    "                                       torch.nn.ReLU(),\n",
    "                                       torch.nn.Dropout(p=0.5),\n",
    "                                       torch.nn.Linear(1024, 128),\n",
    "                                       torch.nn.ReLU(),\n",
    "                                       torch.nn.Dropout(p=0.5),\n",
    "                                       torch.nn.Linear(128, 32),\n",
    "                                       torch.nn.ReLU(),\n",
    "                                       torch.nn.Dropout(p=0.5),\n",
    "                                       torch.nn.Linear(32, 8),\n",
    "                                       torch.nn.ReLU(),\n",
    "                                       torch.nn.Dropout(p=0.5),\n",
    "                                       torch.nn.Linear(8, 2),\n",
    "                                      )\n",
    "\n",
    "for index, parma in enumerate(model.classifier.parameters()):\n",
    "    if index == 6:\n",
    "        parma.requires_grad = True\n",
    "    \n",
    "if use_gpu:\n",
    "    model = model.cuda()\n",
    "\n",
    "\n",
    "cost = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.classifier.parameters(),lr, weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d (3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace)\n",
      "    (2): Conv2d (64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace)\n",
      "    (4): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
      "    (5): Conv2d (64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): ReLU(inplace)\n",
      "    (7): Conv2d (128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): ReLU(inplace)\n",
      "    (9): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
      "    (10): Conv2d (128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace)\n",
      "    (12): Conv2d (256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): ReLU(inplace)\n",
      "    (14): Conv2d (256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): ReLU(inplace)\n",
      "    (16): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
      "    (17): Conv2d (256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): ReLU(inplace)\n",
      "    (19): Conv2d (512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (20): ReLU(inplace)\n",
      "    (21): Conv2d (512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (22): ReLU(inplace)\n",
      "    (23): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
      "    (24): Conv2d (512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (25): ReLU(inplace)\n",
      "    (26): Conv2d (512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (27): ReLU(inplace)\n",
      "    (28): Conv2d (512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (29): ReLU(inplace)\n",
      "    (30): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=25088, out_features=4096)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.5)\n",
      "    (3): Linear(in_features=4096, out_features=1024)\n",
      "    (4): ReLU()\n",
      "    (5): Dropout(p=0.5)\n",
      "    (6): Linear(in_features=1024, out_features=128)\n",
      "    (7): ReLU()\n",
      "    (8): Dropout(p=0.5)\n",
      "    (9): Linear(in_features=128, out_features=32)\n",
      "    (10): ReLU()\n",
      "    (11): Dropout(p=0.5)\n",
      "    (12): Linear(in_features=32, out_features=8)\n",
      "    (13): ReLU()\n",
      "    (14): Dropout(p=0.5)\n",
      "    (15): Linear(in_features=8, out_features=2)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch0/2\n",
      "----------\n",
      "Batch 500, Train Loss:0.2011, Train ACC:100.9500\n",
      "Batch 1000, Train Loss:0.1873, Train ACC:100.5500\n",
      "Batch 1500, Train Loss:0.1842, Train ACC:99.1667\n",
      "Batch 2000, Train Loss:0.1826, Train ACC:99.7875\n",
      "Batch 2500, Train Loss:0.1808, Train ACC:99.8900\n",
      "train  Loss: 0.0900,  Correct: 49.8756\n",
      "val  Loss: 0.0870,  Correct: 50.0000\n",
      "Training time is:2m 0s\n",
      "Epoch1/2\n",
      "----------\n",
      "Batch 500, Train Loss:0.1737, Train ACC:95.0000\n",
      "Batch 1000, Train Loss:0.1735, Train ACC:98.5250\n",
      "Batch 1500, Train Loss:0.1735, Train ACC:98.6333\n",
      "Batch 2000, Train Loss:0.1735, Train ACC:99.3000\n",
      "Batch 2500, Train Loss:0.1735, Train ACC:99.8100\n",
      "train  Loss: 0.0867,  Correct: 50.1244\n",
      "val  Loss: 0.0868,  Correct: 50.0000\n",
      "Training time is:2m 1s\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 5\n",
    "for epoch in range(n_epochs):\n",
    "    since = time.time()\n",
    "    print(\"Epoch{}/{}\".format(epoch, n_epochs))\n",
    "    print(\"-\"*10)\n",
    "    for param in [\"train\", \"val\"]:\n",
    "        if param == \"train\":\n",
    "            model.train = True\n",
    "            model = torch.nn.DataParallel(model)\n",
    "        else:\n",
    "            model.train = False\n",
    "\n",
    "        running_loss = 0.0\n",
    "        running_correct = 0 \n",
    "        batch = 0\n",
    "        for data in data_loader_image[param]:\n",
    "            batch += 1\n",
    "            X, y = data\n",
    "            if use_gpu:\n",
    "                X, y  = Variable(X.cuda()), Variable(y.cuda())\n",
    "            else:\n",
    "                X, y = Variable(X), Variable(y)\n",
    "        \n",
    "            optimizer.zero_grad()\n",
    "            y_pred = model(X)\n",
    "            _, pred = torch.max(y_pred.data, 1)\n",
    "        \n",
    "            loss = cost(y_pred, y)\n",
    "            if param ==\"train\":\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            running_loss += loss.data[0]\n",
    "            running_correct += torch.sum(pred == y.data)\n",
    "            if batch%500 == 0 and param ==\"train\":\n",
    "                print(\"Batch {}, Train Loss:{:.4f}, Train ACC:{:.4f}\".format(\n",
    "                      batch, running_loss/(4*batch), 100*running_correct/(4*batch)))\n",
    "            \n",
    "        epoch_loss = running_loss/len(data_image[param])\n",
    "        epoch_correct = 100*running_correct/len(data_image[param])\n",
    "\n",
    "        print(\"{}  Loss: {:.4f},  Correct: {:.4f}\".format(param, epoch_loss, epoch_correct))\n",
    "    now_time = time.time() - since   \n",
    "    print(\"Training time is:{:.0f}m {:.0f}s\".format(now_time//60, now_time%60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"model_vgg16_finetune.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('model_vgg16_finetune.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageFolder(datasets.ImageFolder):\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            index (int): Index\n",
    "        Returns:\n",
    "            tuple: (image, target) where target is class_index of the target class.\n",
    "        \"\"\"\n",
    "        path, target = self.imgs[index]\n",
    "        img = self.loader(path)\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        if self.target_transform is not None:\n",
    "            target = self.target_transform(target)\n",
    "\n",
    "        return img, target, path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test_img = ImageFolder(root=\"./test/\",\n",
    "                                     transform = transform)\n",
    "data_loader_test_img = torch.utils.data.DataLoader(dataset=data_test_img,\n",
    "                                                   batch_size = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "( 0 , 0 ,.,.) = \n",
      " -1.5014 -1.5357 -1.5870  ...   1.2728  1.2899  1.3242\n",
      " -1.5528 -1.5870 -1.6384  ...   1.2899  1.2728  1.2728\n",
      " -1.6042 -1.6384 -1.6898  ...   1.3584  1.3242  1.3070\n",
      "           ...             ⋱             ...          \n",
      "  0.3994  0.2453  0.0227  ...   0.8789  0.8618  0.8447\n",
      "  0.4508  0.4508  0.2967  ...   0.8447  0.8276  0.8104\n",
      "  1.0502  1.0502  0.6563  ...   0.8104  0.7933  0.7762\n",
      "\n",
      "( 0 , 1 ,.,.) = \n",
      " -1.2304 -1.2654 -1.3354  ...   0.3803  0.3978  0.4328\n",
      " -1.2654 -1.3179 -1.3704  ...   0.3978  0.3803  0.3803\n",
      " -1.3179 -1.3529 -1.4230  ...   0.4678  0.4328  0.4153\n",
      "           ...             ⋱             ...          \n",
      "  0.3102  0.1702 -0.0224  ...   1.1856  1.1506  1.1506\n",
      "  0.3452  0.3627  0.2227  ...   1.1506  1.1155  1.1331\n",
      "  0.9755  0.9755  0.5903  ...   1.0980  1.0805  1.0980\n",
      "\n",
      "( 0 , 2 ,.,.) = \n",
      " -0.8458 -0.8981 -0.9853  ...   0.4265  0.4439  0.4788\n",
      " -0.8981 -0.9504 -1.0376  ...   0.4439  0.4265  0.4265\n",
      " -0.9504 -1.0201 -1.0898  ...   0.4962  0.4614  0.4614\n",
      "           ...             ⋱             ...          \n",
      "  0.2871  0.0779 -0.1661  ...   1.5594  1.5594  1.5420\n",
      "  0.3219  0.2696  0.0779  ...   1.5245  1.5245  1.5245\n",
      "  0.9494  0.8971  0.4439  ...   1.4897  1.4897  1.4897\n",
      "[torch.FloatTensor of size 1x3x224x224]\n",
      "\n",
      "\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "('./test/test/1.jpg',)\n"
     ]
    }
   ],
   "source": [
    "for a,b,c in data_loader_test_img:\n",
    "    print(a)\n",
    "    print(b)\n",
    "    print(c)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ipykernel_launcher.py:10: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "clip = 0.001\n",
    "cnt = 1\n",
    "csv_map = {}\n",
    "\n",
    "for image, label, path in (data_loader_test_img):\n",
    "    images = Variable(image.cuda())\n",
    "    y_pred = model(images)\n",
    "    smax = torch.nn.Softmax()\n",
    "    smax_out = smax(y_pred)[0]\n",
    "    cat_prob = smax_out.data[0]\n",
    "    dog_prob = smax_out.data[1]\n",
    "    prob = dog_prob\n",
    "\n",
    "    if cat_prob > dog_prob:\n",
    "        prob = 1 - cat_prob\n",
    "    prob = np.around(prob, decimals=4)\n",
    "    prob = np.clip(prob, clip, 1-clip)\n",
    "    filepath = path[0].split('/')[-1].split('.')[-2]\n",
    "    if filepath == '0':\n",
    "        print(path)\n",
    "        break\n",
    "    csv_map[filepath] = prob\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_list = []\n",
    "for k,v in csv_map.items():\n",
    "    csv_list.append((k,v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12500"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(csv_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(csv_list)\n",
    "df.columns = ['id','label']\n",
    "df.id = df.id.astype(int)\n",
    "df = df.sort_values('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('result.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('id').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = torchvision.utils.make_grid(image)\n",
    "img = img.numpy().transpose(1,2,0)\n",
    "mean = [0.5,0.5,0.5]\n",
    "std  = [0.5,0.5,0.5]\n",
    "img = img*std+mean\n",
    "print(\"Pred Label:\",[classes[i] for i in pred])\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
