{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import time\n",
    "import pandas as pd\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.6/site-packages/torchvision-0.2.0-py3.6.egg/torchvision/transforms/transforms.py:397: UserWarning: The use of the transforms.RandomSizedCrop transform is deprecated, please use transforms.RandomResizedCrop instead.\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/torchvision-0.2.0-py3.6.egg/torchvision/transforms/transforms.py:156: UserWarning: The use of the transforms.Scale transform is deprecated, please use transforms.Resize instead.\n"
     ]
    }
   ],
   "source": [
    "path = \"./data\"\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "transform = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomSizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        normalize\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Scale(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        normalize\n",
    "    ]),\n",
    "}\n",
    "\n",
    "data_image = {x:datasets.ImageFolder(root = os.path.join(path,x),\n",
    "                                     transform = transform[x])\n",
    "              for x in [\"train\", \"val\"]}\n",
    "\n",
    "data_loader_image = {x:torch.utils.data.DataLoader(dataset=data_image[x],\n",
    "                                                num_workers=4,\n",
    "                                                batch_size=24,\n",
    "                                                pin_memory=True,\n",
    "                                                shuffle = True)\n",
    "                     for x in [\"train\", \"val\"]}\n",
    "\n",
    "dataset_sizes = {x: len(data_loader_image[x]) for x in ['train', 'val']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_gpu = torch.cuda.is_available()\n",
    "print(use_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = data_image['train'].classes\n",
    "classes_index = data_image[\"train\"].class_to_idx\n",
    "# print(classes)\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(u\"训练集个数:\", len(data_image[\"train\"]))\n",
    "print(u\"验证集个数:\", len(data_image[\"val\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(inp, title=None):\n",
    "    \"\"\"显示Tensor类型的图片\"\"\"\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std * inp + mean\n",
    "    plt.figure(figsize=(17, 10))\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    \n",
    "\n",
    "#一批训练集\n",
    "inputs, classes = next(iter(data_loader_image['train']))\n",
    "\n",
    "#对图片制作网格\n",
    "out = torchvision.utils.make_grid(inputs)\n",
    "\n",
    "imshow(out, title=[class_names[i] for i in classes])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = model.state_dict()\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        since = time.time()\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # 每一轮都有一次训练和验证\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "                model.train(True)  # 将模型设置为训练模式\n",
    "            else:\n",
    "                model.train(False)  # 将模型设置为验证模式\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # 迭代数据\n",
    "            for data in data_loader_image[phase]:\n",
    "                # 得到输入数据\n",
    "                inputs, labels = data\n",
    "\n",
    "                # 将他们包装在Variable\n",
    "                if use_gpu:\n",
    "                    inputs = Variable(inputs.cuda())\n",
    "                    labels = Variable(labels.cuda())\n",
    "                else:\n",
    "                    inputs, labels = Variable(inputs), Variable(labels)\n",
    "\n",
    "                # 梯度归零\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # 前向传播\n",
    "                outputs = model(inputs) #1\n",
    "                _, preds = torch.max(outputs.data, 1) #2\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                # 反向传播+参数优化，如果是处于训练时期\n",
    "                if phase == 'train':\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                # 对每次迭代的loss和accuracy求和\n",
    "                running_loss += loss.data[0] \n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "            # 统计每一轮的平均loss和accuracy   \n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects / dataset_sizes[phase]\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # 保存最好的模型\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = model.state_dict()\n",
    "                \n",
    "            print()\n",
    "            \n",
    "        now_time = time.time() - since   \n",
    "        print(\"Training time is:{:.0f}m {:.0f}s\".format(now_time//60, now_time%60))\n",
    "\n",
    "        \n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # 加载模型权重\n",
    "    model.load_state_dict(best_model_wts) # 3\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alexnet',\n",
       " 'densenet',\n",
       " 'densenet121',\n",
       " 'densenet161',\n",
       " 'densenet169',\n",
       " 'densenet201',\n",
       " 'inception',\n",
       " 'inception_v3',\n",
       " 'resnet',\n",
       " 'resnet101',\n",
       " 'resnet152',\n",
       " 'resnet18',\n",
       " 'resnet34',\n",
       " 'resnet50',\n",
       " 'squeezenet',\n",
       " 'squeezenet1_0',\n",
       " 'squeezenet1_1',\n",
       " 'vgg',\n",
       " 'vgg11',\n",
       " 'vgg11_bn',\n",
       " 'vgg13',\n",
       " 'vgg13_bn',\n",
       " 'vgg16',\n",
       " 'vgg16_bn',\n",
       " 'vgg19',\n",
       " 'vgg19_bn']"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torchvision.models as models\n",
    "model_names = sorted(name for name in models.__dict__ if name.islower() and not name.startswith(\"__\"))\n",
    "model_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "arch = 'resnet101'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_conv = models.__dict__[arch](pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 调整模型\n",
    "\n",
    "for param in model_conv.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# 新加的层默认设置 requires_grad=True \n",
    "num_ftrs = model_conv.fc.in_features\n",
    "model_conv.fc = nn.Linear(num_ftrs, 2) # 在resnet10之后增加一个全连接层\n",
    "\n",
    "if use_gpu:\n",
    "    model_conv = model_conv.cuda()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# 仅仅优化最后一层的参数\n",
    "optimizer_conv = optim.SGD(model_conv.fc.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# 每隔7轮学习率变为原来的0.1倍\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_conv, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/24\n",
      "----------\n",
      "train Loss: 0.1543 Acc: 22.4307\n",
      "val Loss: 0.0349 Acc: 23.5048\n",
      "\n",
      "Epoch 1/24\n",
      "----------\n",
      "train Loss: 0.1315 Acc: 22.6514\n",
      "val Loss: 0.0342 Acc: 23.5905\n",
      "\n",
      "Epoch 2/24\n",
      "----------\n",
      "train Loss: 0.1197 Acc: 22.7846\n",
      "val Loss: 0.0269 Acc: 23.6095\n",
      "\n",
      "Epoch 3/24\n",
      "----------\n",
      "train Loss: 0.1199 Acc: 22.7420\n",
      "val Loss: 0.0254 Acc: 23.6286\n",
      "\n",
      "Epoch 4/24\n",
      "----------\n",
      "train Loss: 0.1207 Acc: 22.7719\n",
      "val Loss: 0.0226 Acc: 23.6000\n",
      "\n",
      "Epoch 5/24\n",
      "----------\n",
      "train Loss: 0.1192 Acc: 22.7900\n",
      "val Loss: 0.0270 Acc: 23.6095\n",
      "\n",
      "Epoch 6/24\n",
      "----------\n",
      "train Loss: 0.1156 Acc: 22.8198\n",
      "val Loss: 0.0238 Acc: 23.5810\n",
      "\n",
      "Epoch 7/24\n",
      "----------\n",
      "train Loss: 0.1059 Acc: 22.9328\n",
      "val Loss: 0.0219 Acc: 23.6190\n",
      "\n",
      "Epoch 8/24\n",
      "----------\n",
      "train Loss: 0.1088 Acc: 22.8507\n",
      "val Loss: 0.0236 Acc: 23.6095\n",
      "\n",
      "Epoch 9/24\n",
      "----------\n",
      "train Loss: 0.1098 Acc: 22.9009\n",
      "val Loss: 0.0239 Acc: 23.6000\n",
      "\n",
      "Epoch 10/24\n",
      "----------\n",
      "train Loss: 0.1090 Acc: 22.8966\n",
      "val Loss: 0.0235 Acc: 23.6190\n",
      "\n",
      "Epoch 11/24\n",
      "----------\n",
      "train Loss: 0.1080 Acc: 22.8859\n",
      "val Loss: 0.0228 Acc: 23.6000\n",
      "\n",
      "Epoch 12/24\n",
      "----------\n",
      "train Loss: 0.1080 Acc: 22.8955\n",
      "val Loss: 0.0243 Acc: 23.6190\n",
      "\n",
      "Epoch 13/24\n",
      "----------\n",
      "train Loss: 0.1082 Acc: 22.8977\n",
      "val Loss: 0.0231 Acc: 23.6190\n",
      "\n",
      "Epoch 14/24\n",
      "----------\n",
      "train Loss: 0.1072 Acc: 22.9094\n",
      "val Loss: 0.0258 Acc: 23.5714\n",
      "\n",
      "Epoch 15/24\n",
      "----------\n",
      "train Loss: 0.1075 Acc: 22.9307\n",
      "val Loss: 0.0239 Acc: 23.6095\n",
      "\n",
      "Epoch 16/24\n",
      "----------\n",
      "train Loss: 0.1047 Acc: 22.9584\n",
      "val Loss: 0.0219 Acc: 23.6286\n",
      "\n",
      "Epoch 17/24\n",
      "----------\n",
      "train Loss: 0.1105 Acc: 22.8529\n",
      "val Loss: 0.0239 Acc: 23.6286\n",
      "\n",
      "Epoch 18/24\n",
      "----------\n",
      "train Loss: 0.1105 Acc: 22.8593\n",
      "val Loss: 0.0231 Acc: 23.6381\n",
      "\n",
      "Epoch 19/24\n",
      "----------\n",
      "train Loss: 0.1044 Acc: 22.9030\n",
      "val Loss: 0.0236 Acc: 23.6190\n",
      "\n",
      "Epoch 20/24\n",
      "----------\n",
      "train Loss: 0.1066 Acc: 22.9041\n",
      "val Loss: 0.0233 Acc: 23.6286\n",
      "\n",
      "Epoch 21/24\n",
      "----------\n",
      "train Loss: 0.1092 Acc: 22.8870\n",
      "val Loss: 0.0234 Acc: 23.6095\n",
      "\n",
      "Epoch 22/24\n",
      "----------\n",
      "train Loss: 0.1134 Acc: 22.8156\n",
      "val Loss: 0.0250 Acc: 23.6286\n",
      "\n",
      "Epoch 23/24\n",
      "----------\n",
      "train Loss: 0.1060 Acc: 22.8977\n",
      "val Loss: 0.0249 Acc: 23.6190\n",
      "\n",
      "Epoch 24/24\n",
      "----------\n",
      "train Loss: 0.1050 Acc: 22.9307\n",
      "val Loss: 0.0227 Acc: 23.6381\n",
      "\n",
      "Training complete in 27m 43s\n",
      "Best val Acc: 23.638095\n"
     ]
    }
   ],
   "source": [
    "model_conv = train_model(model_conv, criterion, optimizer_conv,\n",
    "                         exp_lr_scheduler, num_epochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def visualize_model(model, num_images=6):\n",
    "    images_so_far = 0\n",
    "    fig = plt.figure()\n",
    "\n",
    "    for i, data in enumerate(data_loader_image['val']):\n",
    "        inputs, labels = data\n",
    "        if use_gpu:\n",
    "            inputs, labels = Variable(inputs.cuda()), Variable(labels.cuda())\n",
    "        else:\n",
    "            inputs, labels = Variable(inputs), Variable(labels)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs.data, 1)\n",
    "\n",
    "        for j in range(inputs.size()[0]):\n",
    "            images_so_far += 1\n",
    "            ax = plt.subplot(num_images//2, 2, images_so_far)\n",
    "            ax.axis('off')\n",
    "            ax.set_title('predicted: {}'.format(class_names[preds[j]]))\n",
    "            imshow(inputs.cpu().data[j])\n",
    "\n",
    "            if images_so_far == num_images:\n",
    "                return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "visualize_model(model_conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "torch.save(model_conv.state_dict(), \"model_%s_finetune.pkl\" % arch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('model_%s_finetune.pkl' % arch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dir(torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ImageFolder(datasets.ImageFolder):\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            index (int): Index\n",
    "        Returns:\n",
    "            tuple: (image, target) where target is class_index of the target class.\n",
    "        \"\"\"\n",
    "        path, target = self.imgs[index]\n",
    "        img = self.loader(path)\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        if self.target_transform is not None:\n",
    "            target = self.target_transform(target)\n",
    "\n",
    "        return img, target, path\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_test_img = ImageFolder(root=\"./test/\",\n",
    "                                     transform = transform['val'])\n",
    "data_loader_test_img = torch.utils.data.DataLoader(dataset=data_test_img,\n",
    "                                                   batch_size = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for a,b,c in data_loader_test_img:\n",
    "    print(a)\n",
    "    print(b)\n",
    "    print(c)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:10: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "clip = 0.005\n",
    "cnt = 1\n",
    "csv_map = {}\n",
    "\n",
    "for image, label, path in data_loader_test_img:\n",
    "    images = Variable(image.cuda())\n",
    "    y_pred = model_conv(images)\n",
    "    smax = torch.nn.Softmax()\n",
    "    smax_out = smax(y_pred)[0]\n",
    "    cat_prob = smax_out.data[0]\n",
    "    dog_prob = smax_out.data[1]\n",
    "    prob = dog_prob\n",
    "\n",
    "    if cat_prob > dog_prob:\n",
    "        prob = 1 - cat_prob\n",
    "    prob = np.around(prob, decimals=4)\n",
    "    prob = np.clip(prob, clip, 1-clip)\n",
    "    filepath = path[0].split('/')[-1].split('.')[-2]\n",
    "    \n",
    "    csv_map[filepath] = prob\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12500"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_list = []\n",
    "for k,v in csv_map.items():\n",
    "    csv_list.append((k,v))\n",
    "\n",
    "len(csv_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(csv_list)\n",
    "df.columns = ['id','label']\n",
    "df.id = df.id.astype(int)\n",
    "df = df.sort_values('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('result_%s.csv' % arch,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'result_resnet101.csv'"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'result_%s.csv' % arch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.groupby('id').count()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
