{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import datasets,transforms, models\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.autograd import Variable \n",
    "import time\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/miniconda3/lib/python3.6/site-packages/torchvision/transforms/transforms.py:397: UserWarning: The use of the transforms.RandomSizedCrop transform is deprecated, please use transforms.RandomResizedCrop instead.\n",
      "  \"please use transforms.RandomResizedCrop instead.\")\n"
     ]
    }
   ],
   "source": [
    "path = \"./data\"\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "transform = transforms.Compose([\n",
    "                             # transforms.Lambda(shear),\n",
    "                             transforms.RandomSizedCrop(224),\n",
    "                             transforms.RandomHorizontalFlip(),\n",
    "                             transforms.ToTensor(),\n",
    "                             normalize,\n",
    "                                 ])\n",
    "\n",
    "data_image = {x:datasets.ImageFolder(root = os.path.join(path,x),\n",
    "                                     transform = transform)\n",
    "              for x in [\"train\", \"val\"]}\n",
    "\n",
    "data_loader_image = {x:torch.utils.data.DataLoader(dataset=data_image[x],\n",
    "                                                num_workers=4,\n",
    "                                                batch_size=8,\n",
    "                                                pin_memory=True,\n",
    "                                                shuffle = True)\n",
    "                     for x in [\"train\", \"val\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "use_gpu = torch.cuda.is_available()\n",
    "print(use_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cat', 'dog']\n",
      "{'cat': 0, 'dog': 1}\n"
     ]
    }
   ],
   "source": [
    "classes = data_image[\"train\"].classes\n",
    "classes_index = data_image[\"train\"].class_to_idx\n",
    "print(classes)\n",
    "print(classes_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集个数: 22500\n",
      "验证集个数: 2499\n"
     ]
    }
   ],
   "source": [
    "print(u\"训练集个数:\", len(data_image[\"train\"]))\n",
    "print(u\"验证集个数:\", len(data_image[\"val\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = next(iter(data_loader_image[\"train\"]))\n",
    "mean = [0.5,0.5,0.5]\n",
    "std  = [0.5,0.5,0.5]\n",
    "img = torchvision.utils.make_grid(X_train)\n",
    "img = img.numpy().transpose((1,2,0))\n",
    "img = img*std+mean\n",
    "\n",
    "print([classes[i] for i in y_train])\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.vgg16(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d (3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace)\n",
      "    (2): Conv2d (64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace)\n",
      "    (4): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
      "    (5): Conv2d (64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): ReLU(inplace)\n",
      "    (7): Conv2d (128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): ReLU(inplace)\n",
      "    (9): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
      "    (10): Conv2d (128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace)\n",
      "    (12): Conv2d (256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): ReLU(inplace)\n",
      "    (14): Conv2d (256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): ReLU(inplace)\n",
      "    (16): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
      "    (17): Conv2d (256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): ReLU(inplace)\n",
      "    (19): Conv2d (512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (20): ReLU(inplace)\n",
      "    (21): Conv2d (512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (22): ReLU(inplace)\n",
      "    (23): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
      "    (24): Conv2d (512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (25): ReLU(inplace)\n",
      "    (26): Conv2d (512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (27): ReLU(inplace)\n",
      "    (28): Conv2d (512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (29): ReLU(inplace)\n",
      "    (30): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=25088, out_features=4096)\n",
      "    (1): ReLU(inplace)\n",
      "    (2): Dropout(p=0.5)\n",
      "    (3): Linear(in_features=4096, out_features=4096)\n",
      "    (4): ReLU(inplace)\n",
      "    (5): Dropout(p=0.5)\n",
      "    (6): Linear(in_features=4096, out_features=1000)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-2\n",
    "for parma in model.parameters():\n",
    "    parma.requires_grad = False\n",
    "\n",
    "model.fc = torch.nn.Sequential(torch.nn.Linear(1000, 2))\n",
    "\n",
    "for param in model.fc.parameters():\n",
    "    param.requires_grad = True\n",
    "    \n",
    "if use_gpu:\n",
    "    model = model.cuda()\n",
    "\n",
    "\n",
    "cost = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.fc.parameters(),lr, weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d (3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace)\n",
      "    (2): Conv2d (64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace)\n",
      "    (4): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
      "    (5): Conv2d (64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): ReLU(inplace)\n",
      "    (7): Conv2d (128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): ReLU(inplace)\n",
      "    (9): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
      "    (10): Conv2d (128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace)\n",
      "    (12): Conv2d (256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): ReLU(inplace)\n",
      "    (14): Conv2d (256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): ReLU(inplace)\n",
      "    (16): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
      "    (17): Conv2d (256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): ReLU(inplace)\n",
      "    (19): Conv2d (512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (20): ReLU(inplace)\n",
      "    (21): Conv2d (512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (22): ReLU(inplace)\n",
      "    (23): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
      "    (24): Conv2d (512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (25): ReLU(inplace)\n",
      "    (26): Conv2d (512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (27): ReLU(inplace)\n",
      "    (28): Conv2d (512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (29): ReLU(inplace)\n",
      "    (30): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=25088, out_features=4096)\n",
      "    (1): ReLU(inplace)\n",
      "    (2): Dropout(p=0.5)\n",
      "    (3): Linear(in_features=4096, out_features=4096)\n",
      "    (4): ReLU(inplace)\n",
      "    (5): Dropout(p=0.5)\n",
      "    (6): Linear(in_features=4096, out_features=1000)\n",
      "  )\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=1000, out_features=2)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch0/1\n",
      "----------\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Traceback (most recent call last):\n  File \"/usr/local/miniconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 64, in _pin_memory_loop\n    batch = pin_memory_batch(batch)\n  File \"/usr/local/miniconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 132, in pin_memory_batch\n    return [pin_memory_batch(sample) for sample in batch]\n  File \"/usr/local/miniconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 132, in <listcomp>\n    return [pin_memory_batch(sample) for sample in batch]\n  File \"/usr/local/miniconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 126, in pin_memory_batch\n    return batch.pin_memory()\n  File \"/usr/local/miniconda3/lib/python3.6/site-packages/torch/tensor.py\", line 82, in pin_memory\n    return type(self)().set_(storage.pin_memory()).view_as(self)\n  File \"/usr/local/miniconda3/lib/python3.6/site-packages/torch/storage.py\", line 83, in pin_memory\n    allocator = torch.cuda._host_allocator()\n  File \"/usr/local/miniconda3/lib/python3.6/site-packages/torch/cuda/__init__.py\", line 312, in _host_allocator\n    _lazy_init()\n  File \"/usr/local/miniconda3/lib/python3.6/site-packages/torch/cuda/__init__.py\", line 120, in _lazy_init\n    _check_driver()\n  File \"/usr/local/miniconda3/lib/python3.6/site-packages/torch/cuda/__init__.py\", line 55, in _check_driver\n    raise AssertionError(\"Torch not compiled with CUDA enabled\")\nAssertionError: Torch not compiled with CUDA enabled\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-eb94c05a571b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mrunning_correct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_loader_image\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m             \u001b[0mbatch\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/miniconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    208\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreorder_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_next_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m     \u001b[0mnext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__next__\u001b[0m  \u001b[0;31m# Python 2 compatibility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/miniconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_next_batch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    228\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_put_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Traceback (most recent call last):\n  File \"/usr/local/miniconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 64, in _pin_memory_loop\n    batch = pin_memory_batch(batch)\n  File \"/usr/local/miniconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 132, in pin_memory_batch\n    return [pin_memory_batch(sample) for sample in batch]\n  File \"/usr/local/miniconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 132, in <listcomp>\n    return [pin_memory_batch(sample) for sample in batch]\n  File \"/usr/local/miniconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 126, in pin_memory_batch\n    return batch.pin_memory()\n  File \"/usr/local/miniconda3/lib/python3.6/site-packages/torch/tensor.py\", line 82, in pin_memory\n    return type(self)().set_(storage.pin_memory()).view_as(self)\n  File \"/usr/local/miniconda3/lib/python3.6/site-packages/torch/storage.py\", line 83, in pin_memory\n    allocator = torch.cuda._host_allocator()\n  File \"/usr/local/miniconda3/lib/python3.6/site-packages/torch/cuda/__init__.py\", line 312, in _host_allocator\n    _lazy_init()\n  File \"/usr/local/miniconda3/lib/python3.6/site-packages/torch/cuda/__init__.py\", line 120, in _lazy_init\n    _check_driver()\n  File \"/usr/local/miniconda3/lib/python3.6/site-packages/torch/cuda/__init__.py\", line 55, in _check_driver\n    raise AssertionError(\"Torch not compiled with CUDA enabled\")\nAssertionError: Torch not compiled with CUDA enabled\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 1\n",
    "for epoch in range(n_epochs):\n",
    "    since = time.time()\n",
    "    print(\"Epoch{}/{}\".format(epoch, n_epochs))\n",
    "    print(\"-\"*10)\n",
    "    for param in [\"train\", \"val\"]:\n",
    "        if param == \"train\":\n",
    "            model.train = True\n",
    "            model = torch.nn.DataParallel(model)\n",
    "        else:\n",
    "            model.train = False\n",
    "\n",
    "        running_loss = 0.0\n",
    "        running_correct = 0 \n",
    "        batch = 0\n",
    "        for data in data_loader_image[param]:\n",
    "            batch += 1\n",
    "            X, y = data\n",
    "            if use_gpu:\n",
    "                X, y  = Variable(X.cuda()), Variable(y.cuda())\n",
    "            else:\n",
    "                X, y = Variable(X), Variable(y)\n",
    "        \n",
    "            optimizer.zero_grad()\n",
    "            y_pred = model(X)\n",
    "            _, pred = torch.max(y_pred.data, 1)\n",
    "        \n",
    "            loss = cost(y_pred, y)\n",
    "            if param ==\"train\":\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            running_loss += loss.data[0]\n",
    "            running_correct += torch.sum(pred == y.data)\n",
    "            if batch%500 == 0 and param ==\"train\":\n",
    "                print(\"Batch {}, Train Loss:{:.4f}, Train ACC:{:.4f}\".format(\n",
    "                      batch, running_loss/(4*batch), 100*running_correct/(4*batch)))\n",
    "            \n",
    "        epoch_loss = running_loss/len(data_image[param])\n",
    "        epoch_correct = 100*running_correct/len(data_image[param])\n",
    "\n",
    "        print(\"{}  Loss: {:.4f},  Correct: {:.4f}\".format(param, epoch_loss, epoch_correct))\n",
    "    now_time = time.time() - since   \n",
    "    print(\"Training time is:{:.0f}m {:.0f}s\".format(now_time//60, now_time%60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"model_vgg16_finetune.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('model_vgg16_finetune.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageFolder(datasets.ImageFolder):\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            index (int): Index\n",
    "        Returns:\n",
    "            tuple: (image, target) where target is class_index of the target class.\n",
    "        \"\"\"\n",
    "        path, target = self.imgs[index]\n",
    "        img = self.loader(path)\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        if self.target_transform is not None:\n",
    "            target = self.target_transform(target)\n",
    "\n",
    "        return img, target, path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test_img = ImageFolder(root=\"./test/\",\n",
    "                                     transform = transform)\n",
    "data_loader_test_img = torch.utils.data.DataLoader(dataset=data_test_img,\n",
    "                                                   batch_size = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "( 0 , 0 ,.,.) = \n",
      " -1.5014 -1.5357 -1.5870  ...   1.2728  1.2899  1.3242\n",
      " -1.5528 -1.5870 -1.6384  ...   1.2899  1.2728  1.2728\n",
      " -1.6042 -1.6384 -1.6898  ...   1.3584  1.3242  1.3070\n",
      "           ...             ⋱             ...          \n",
      "  0.3994  0.2453  0.0227  ...   0.8789  0.8618  0.8447\n",
      "  0.4508  0.4508  0.2967  ...   0.8447  0.8276  0.8104\n",
      "  1.0502  1.0502  0.6563  ...   0.8104  0.7933  0.7762\n",
      "\n",
      "( 0 , 1 ,.,.) = \n",
      " -1.2304 -1.2654 -1.3354  ...   0.3803  0.3978  0.4328\n",
      " -1.2654 -1.3179 -1.3704  ...   0.3978  0.3803  0.3803\n",
      " -1.3179 -1.3529 -1.4230  ...   0.4678  0.4328  0.4153\n",
      "           ...             ⋱             ...          \n",
      "  0.3102  0.1702 -0.0224  ...   1.1856  1.1506  1.1506\n",
      "  0.3452  0.3627  0.2227  ...   1.1506  1.1155  1.1331\n",
      "  0.9755  0.9755  0.5903  ...   1.0980  1.0805  1.0980\n",
      "\n",
      "( 0 , 2 ,.,.) = \n",
      " -0.8458 -0.8981 -0.9853  ...   0.4265  0.4439  0.4788\n",
      " -0.8981 -0.9504 -1.0376  ...   0.4439  0.4265  0.4265\n",
      " -0.9504 -1.0201 -1.0898  ...   0.4962  0.4614  0.4614\n",
      "           ...             ⋱             ...          \n",
      "  0.2871  0.0779 -0.1661  ...   1.5594  1.5594  1.5420\n",
      "  0.3219  0.2696  0.0779  ...   1.5245  1.5245  1.5245\n",
      "  0.9494  0.8971  0.4439  ...   1.4897  1.4897  1.4897\n",
      "[torch.FloatTensor of size 1x3x224x224]\n",
      "\n",
      "\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "('./test/test/1.jpg',)\n"
     ]
    }
   ],
   "source": [
    "for a,b,c in data_loader_test_img:\n",
    "    print(a)\n",
    "    print(b)\n",
    "    print(c)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ipykernel_launcher.py:10: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "clip = 0.001\n",
    "cnt = 1\n",
    "csv_map = {}\n",
    "\n",
    "for image, label, path in (data_loader_test_img):\n",
    "    images = Variable(image.cuda())\n",
    "    y_pred = model(images)\n",
    "    smax = torch.nn.Softmax()\n",
    "    smax_out = smax(y_pred)[0]\n",
    "    cat_prob = smax_out.data[0]\n",
    "    dog_prob = smax_out.data[1]\n",
    "    prob = dog_prob\n",
    "\n",
    "    if cat_prob > dog_prob:\n",
    "        prob = 1 - cat_prob\n",
    "    prob = np.around(prob, decimals=4)\n",
    "    prob = np.clip(prob, clip, 1-clip)\n",
    "    filepath = path[0].split('/')[-1].split('.')[-2]\n",
    "    if filepath == '0':\n",
    "        print(path)\n",
    "        break\n",
    "    csv_map[filepath] = prob\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_list = []\n",
    "for k,v in csv_map.items():\n",
    "    csv_list.append((k,v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12500"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(csv_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(csv_list)\n",
    "df.columns = ['id','label']\n",
    "df.id = df.id.astype(int)\n",
    "df = df.sort_values('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('result.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('id').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = torchvision.utils.make_grid(image)\n",
    "img = img.numpy().transpose(1,2,0)\n",
    "mean = [0.5,0.5,0.5]\n",
    "std  = [0.5,0.5,0.5]\n",
    "img = img*std+mean\n",
    "print(\"Pred Label:\",[classes[i] for i in pred])\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
